## 1. KullanÄ±labilecek Ã–lÃ§Ã¼tler

EÄŸitim veya test performansÄ±nÄ± deÄŸerlendirirken genellikle ÅŸu metrikler kullanÄ±lÄ±r:
| Ã–lÃ§Ã¼t                       | AÃ§Ä±klama                                               | KullanÄ±m AmacÄ±                                        |
| --------------------------- | ------------------------------------------------------ | ----------------------------------------------------- |
| **Accuracy (DoÄŸruluk)**     | DoÄŸru tahmin edilen Ã¶rneklerin toplam Ã¶rneÄŸe oranÄ±     | En temel Ã¶lÃ§Ã¼t. Dengeli veri kÃ¼melerinde uygundur.    |
| **Precision (Kesinlik)**    | Pozitif tahminlerin gerÃ§ekten pozitif olma oranÄ±       | YanlÄ±ÅŸ pozitifleri azaltmak istediÄŸimizde Ã¶nemlidir.  |
| **Recall (DuyarlÄ±lÄ±k)**     | GerÃ§ek pozitiflerin ne kadarÄ±nÄ±n doÄŸru tahmin edildiÄŸi | KaÃ§Ä±rÄ±lan Ã¶rnekleri azaltmak istediÄŸimizde Ã¶nemlidir. |
| **F1-Score**                | Precision ve Recallâ€™un harmonik ortalamasÄ±             | Dengesiz verilerde dengeli bir Ã¶lÃ§Ã¼ saÄŸlar.           |
| **Error Rate (Hata OranÄ±)** | 1 - Accuracy                                           | Hata Ã¼zerinden ifade etmek istiyorsak.                |


## 2. Bu GÃ¶rev Ä°Ã§in En Uygun Ã–lÃ§Ã¼t

Bu bir sÄ±nÄ±flandÄ±rma problemi (10 sÄ±nÄ±f: 0â€“9) olduÄŸundan,
ve MNIST gibi dengeli bir veri kÃ¼mesi Ã¼zerinde eÄŸitildiÄŸi iÃ§in,
en anlamlÄ± Ã¶lÃ§Ã¼t genellikle â€œdoÄŸruluk (accuracy)â€ olur.

Ancak bizim ek testlerimiz artÄ±k modelin gÃ¶rmediÄŸi farklÄ± bir veri daÄŸÄ±lÄ±mÄ±nÄ± (senin el yazÄ±n) temsil ediyor.
Yani burada asÄ±l Ã¶nemli olan:

ğŸ”¸ Modelin genelleme kabiliyeti
ğŸ”¸ FarklÄ± stil ve yazÄ±m biÃ§imlerini doÄŸru tanÄ±ma baÅŸarÄ±sÄ±

Bu durumda tek baÅŸÄ±na doÄŸruluk yanÄ±ltÄ±cÄ± olabilir.
DolayÄ±sÄ±yla F1 skoru burada daha uygun bir Ã¶lÃ§Ã¼ttÃ¼r Ã§Ã¼nkÃ¼:

Her sÄ±nÄ±fÄ±n (0â€“9) tahmin baÅŸarÄ±sÄ±nÄ± dengeli biÃ§imde yansÄ±tÄ±r,

Hem yanlÄ±ÅŸ pozitifleri (Ã¶rneÄŸin 3â€™Ã¼ 8 sanma) hem de yanlÄ±ÅŸ negatifleri (Ã¶rneÄŸin 8â€™i hiÃ§ bulamama) dikkate alÄ±r.

## 3. Neden F1 Skoru?

Bizim sonuÃ§larÄ±na bakalÄ±m:

| GerÃ§ek | Tahmin | OlasÄ±lÄ±k |
| ------ | ------ | -------- |
| 4      | 8      | 96.2%    |
| 3      | 7      | 78.8%    |
| 9      | 3      | 77.6%    |
| 2      | 2      | 99.4%    |
| 7      | 1      | 46.8%    |


DoÄŸruluk oranÄ± = 1 / 5 = %20
Ancak model bazÄ± hatalÄ± tahminlerinde yÃ¼ksek gÃ¼venle yanlÄ±ÅŸ sÃ¶ylÃ¼yor (%96 gibi).
Bu, modelin overfitting yaptÄ±ÄŸÄ±nÄ± (MNIST verisini ezberlediÄŸini) gÃ¶sterir.

F1 skoru ise bu tÃ¼r durumlarda, yanlÄ±ÅŸ tahminleri (Ã¶zellikle karÄ±ÅŸtÄ±rÄ±lan rakamlarÄ±) daha aÄŸÄ±r cezalandÄ±rdÄ±ÄŸÄ± iÃ§in daha gerÃ§ekÃ§i bir performans Ã¶lÃ§Ã¼tÃ¼ sunar.

## 4. Ã–zet SonuÃ§
| Durum                                        | En uygun Ã¶lÃ§Ã¼t                        | Neden                                                                        |
| -------------------------------------------- | ------------------------------------- | ---------------------------------------------------------------------------- |
| **MNIST test verisinde**                     | **Accuracy (DoÄŸruluk)**               | Veri dengeli, sÄ±nÄ±flar eÅŸit sayÄ±da.                                          |
| **El yazÄ±mda (gerÃ§ek dÃ¼nya testinde)**       | **F1 Skoru veya Ortalama Hata OranÄ±** | Model farklÄ± daÄŸÄ±lÄ±mda genelleyemiyor, F1 sÄ±nÄ±flar arasÄ± dengeyi gÃ¶steriyor. |
## Confusion Matrix
<img width="575" height="470" alt="matrix" src="https://github.com/user-attachments/assets/10fce95f-f16b-4216-a265-d57b2310afe2" />

SÄ±nÄ±f BazlÄ± DeÄŸerler:

                   precision    recall  f1-score   support

    1                 0.000     0.000     0.000       0
    2                 1.000     1.000     1.000       1
    3                 0.000     0.000     0.000       1
    4                 0.000     0.000     0.000       1
    7                 0.000     0.000     0.000       1
    8                 0.000     0.000     0.000       0
    9                 0.000     0.000     0.000       1

    accuracy                              0.200       5
    macro avg         0.143     0.143     0.143       5
    weighted avg      0.200     0.200     0.200       5
